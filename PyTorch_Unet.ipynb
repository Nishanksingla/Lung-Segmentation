{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image processing package\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet_pytorch import UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not WORKING. \n",
    "# You have to initialize conv layers in init functiion otherwise forward function keep initializing it at every step.\n",
    "# Can not do like Keras in Pytorch.\n",
    "# class LungSegmentationNet(nn.Module):\n",
    "#     def __init__(self, depth=5, root_filter=64):\n",
    "#         super(LungSegmentationNet, self).__init__()\n",
    "#         self.depth = depth\n",
    "#         self.root_filter = root_filter\n",
    "#         print(\"depth: {}, root filter: {}\".format(self.depth, self.root_filter))\n",
    "    \n",
    "#     # Down sampling\n",
    "#     def forward(self, x):\n",
    "#         long_connection_store = {}\n",
    "#         input_channels = 1\n",
    "#         print(\"UP SAMPLING\")\n",
    "#         for i in range(self.depth):\n",
    "#             out_channel = 2**i * self.root_filter\n",
    "#             print(out_channel)\n",
    "#             x = F.relu(nn.Conv2d(input_channels, out_channel, 3, padding=1)(x))\n",
    "#             x = F.relu(nn.Conv2d(out_channel, out_channel, 3, padding=1)(x))\n",
    "\n",
    "#             if i<self.depth-1:\n",
    "#                 long_connection_store[str(i)] = x\n",
    "#                 x = F.max_pool2d(x, kernel_size=2)\n",
    "#             input_channels = out_channel\n",
    "\n",
    "#         print(\"x.shape: {}\".format(x.shape))\n",
    "#         print(\"DOWN SAMPLING\")\n",
    "        \n",
    "#         for i in range(self.depth - 2, -1, -1):\n",
    "#             out_channel = 2**(i) * self.root_filter\n",
    "#             print(\"input_channels: {}\".format(input_channels))\n",
    "#             print(\"out_channel: {}\".format(out_channel))\n",
    "            \n",
    "#             # long connection from down sampling path.\n",
    "#             long_connection = long_connection_store[str(i)]\n",
    "#             print(\"long_connection shape: {}\".format(long_connection.shape))\n",
    "            \n",
    "#             up1 = nn.Upsample(scale_factor=2)(x)\n",
    "#             print(\"up1 shape: {}\".format(up1.shape))\n",
    "            \n",
    "#             up_conv1 = F.relu(nn.Conv2d(input_channels, out_channel, 3, padding=1)(up1))\n",
    "#             print(\"upsamplingConv : {}\".format(up_conv1.shape))\n",
    "            \n",
    "#             up_conc = torch.cat((up_conv1, long_connection), dim=1)\n",
    "#             print(\"up_conc : {}\\n\".format(up_conc.shape))\n",
    "            \n",
    "#             #  Convolutions\n",
    "#             up_conv1 = F.relu(nn.Conv2d(input_channels, out_channel, 3, padding=1)(up_conc))\n",
    "#             up_conv2 = F.relu(nn.Conv2d(out_channel, out_channel, 3, padding=1)(up_conv1))\n",
    "\n",
    "#             x = up_conv2\n",
    "#             input_channels = out_channel\n",
    "#         print(\"FINAL shape: {}\".format(x.shape))\n",
    "#         x = F.sigmoid(nn.Conv2d(input_channels, 1, 1, padding=0)(x))\n",
    "#         print(\"FINAL shape: {}\".format(x.shape))\n",
    "#         return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unet = LungSegmentationNet(5, 64)\n",
    "# list(unet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "channels = 1\n",
    "height = 256\n",
    "width = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.randn(batch_size, channels, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from torchvision import models\n",
    "# model = models.vgg16()\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch is channel first instead of channel last as in Keras\n",
    "class LungSegmentationDataGen(Dataset):\n",
    "    def __init__(self, dataset, root_dir, args, transforms=None):\n",
    "        self.dataset = dataset\n",
    "        self.root_dir = root_dir\n",
    "        self.args = args\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def preprocess_image(self, path):\n",
    "        im = Image.open(path)\n",
    "        im = ImageOps.grayscale(im)\n",
    "        im = im.resize((self.args.height, self.args.width))  # parameterize height and width\n",
    "        img = np.array(im)\n",
    "        img = img/255.\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        return img\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.dataset[idx]\n",
    "        img_name, mask_name = sample.rstrip().split(\",\")\n",
    "        \n",
    "        image = self.preprocess_image(os.path.join(self.root_dir, \"images\", img_name.strip()))\n",
    "        mask = self.preprocess_image(os.path.join(self.root_dir, \"masks\", mask_name.strip()))\n",
    "#         print(image.dtype, image.shape)\n",
    "#         print(mask.dtype, mask.shape)\n",
    "        # Use albumentation package for augmenting images and mask with same transformations\n",
    "        \n",
    "        # numpy uses float64 as their default type, so call float() on these tensors before passing them to the TensorDataset \n",
    "        return torch.from_numpy(image).float(), torch.from_numpy(mask).float()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(y_true, y_pred):\n",
    "    smooth = 1\n",
    "    y_true_flatten = y_true.view(-1)\n",
    "    y_pred_flatten = y_pred.view(-1)\n",
    "    intersection = 2 * torch.sum(y_true_flatten * y_pred_flatten)\n",
    "    union = torch.sum(y_true_flatten) + torch.sum(y_pred_flatten)\n",
    "    dice_score = (intersection + smooth)/(union + smooth)\n",
    "    return dice_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training steps\n",
    "1. Define the train and validation set data loaders\n",
    "2. Find the device\n",
    "3. Create the model object and put it in device\n",
    "4. Define loss function\n",
    "5. Define the optimizer\n",
    "6. Training Loop\n",
    "        6.1 Epochs for-loop\n",
    "            6.2 Phase for-loop (Train and Val) [\"train\", \"val\"]\n",
    "                6.3 Dataloader loop i.e. loop over batches of the dataset\n",
    "                    6.4 Get the batch data and put the data in device. Below steps are going over a single batch\n",
    "                    6.5 call optimizer.zero_grad()\n",
    "                    6.6 Set grad enabled scope with statement(True for train and False for val)\n",
    "                        6.7 pass the input data through model \n",
    "                        6.8 Calculate the loss\n",
    "                        6.9 If the phase is train then call loss.backward() and optimizer.step() and Also you can collect the loss in a list\n",
    "                        6.10 If the phase is val, then you can store the loss or something else that makes sense\n",
    "                    6.11 If phase is train and print loss summary after certain number of steps.\n",
    "                6.12 If the phase is val, you can calculate and store best_acc(for any metric you want to use) and current_acc\n",
    "                     and based on the comparison between best and current accuracy save the model. HERE whole data loop is finished. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    def __init__(self):\n",
    "        self.batch_size = 2\n",
    "        self.model_depth = 5\n",
    "        self.width = 256\n",
    "        self.root_filter_size = 32\n",
    "        self.epochs = 100\n",
    "        self.height = 256\n",
    "        self.weights = \"trained_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    dataset = open(\"dataset.csv\", \"r\").readlines()\n",
    "    train_set = dataset[:600]\n",
    "    val_set = dataset[600:]\n",
    "    root_dir = root_dir = \"data/Lung_Segmentation/\"\n",
    "\n",
    "    train_data = LungSegmentationDataGen(train_set, root_dir, args)\n",
    "    val_data = LungSegmentationDataGen(val_set, root_dir, args)\n",
    "\n",
    "    train_dataloader = DataLoader(train_data, batch_size=5, shuffle=True, num_workers=4)\n",
    "\n",
    "    val_dataloader = DataLoader(val_data, batch_size=5, shuffle=True, num_workers=4)\n",
    "    \n",
    "    dataloaders = {\n",
    "        \"train\": train_dataloader,\n",
    "        \"val\": val_dataloader\n",
    "    }\n",
    "\n",
    "    dataset_sizes = {\"train\": len(train_set), \"val\": len(val_set)}\n",
    "\n",
    "    print(\"dataset_sizes: {}\".format(dataset_sizes))\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model = UNet(in_channels=1)\n",
    "    #print(\"MODEL: {}\".format(model))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    #optimizer = optim.Adam(unet.parameters(), lr=args.lr)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    \n",
    "    loss_train = []\n",
    "    loss_valid = []\n",
    "    \n",
    "    current_mean_dsc = 0.0\n",
    "    best_validation_dsc = 0.0\n",
    "\n",
    "    step = 0\n",
    "    epochs = args.epochs\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, epochs - 1))\n",
    "        print('-' * 10)\n",
    "        dice_score_list = []\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for i, data in enumerate(dataloaders[phase]):\n",
    "                inputs, y_true = data\n",
    "                inputs = inputs.to(device)\n",
    "                y_true = y_true.to(device)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    y_pred = model(inputs)\n",
    "                    \n",
    "                    loss = dice_loss(y_true, y_pred)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        #print(\"step: {}, train_loss: {}\".format(i, loss))\n",
    "                        loss_train.append(loss.item())\n",
    "                        \n",
    "                        # calculate the gradients based on loss\n",
    "                        loss.backward()\n",
    "                        \n",
    "                        # update the weights\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                    if phase == \"val\":\n",
    "                        loss_valid.append(loss.item())\n",
    "                        dsc = dice_score(y_true, y_pred)\n",
    "                        print(\"step: {}, val_loss: {}, val dice_score: {}\".format(i, loss, dsc))\n",
    "                        dice_score_list.append(dsc.detach().numpy())\n",
    "                        \n",
    "                        \n",
    "                if phase == \"train\" and (i + 1) % 10 == 0:\n",
    "                    print(\"step:{}, train_loss: {}\".format(i+1, np.mean(loss_train)))\n",
    "                    loss_train = []\n",
    "            if phase == \"val\":\n",
    "                print(\"mean val_loss: {}\".format(np.mean(loss_valid)))\n",
    "                loss_valid = []\n",
    "                current_mean_dsc = np.mean(dice_score_list)\n",
    "                print(\"validation set dice_score: {}\".format(current_mean_dsc))\n",
    "                if current_mean_dsc > best_validation_dsc:\n",
    "                    best_validation_dsc = current_mean_dsc\n",
    "                    print(\"best dice_score on val set: {}\".format(best_validation_dsc))\n",
    "                    torch.save(model.state_dict(), os.path.join(args.weights, \"unet_{0:.2f}.pt\".format(best_validation_dsc)))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_sizes: {'train': 600, 'val': 104}\n",
      "Epoch 0/99\n",
      "----------\n",
      "PHASE: train\n",
      "step:10, train_loss: 0.5429947018623352\n",
      "step:20, train_loss: 0.4225769817829132\n",
      "step:30, train_loss: 0.389515346288681\n",
      "step:40, train_loss: 0.3467102885246277\n",
      "step:50, train_loss: 0.32322834730148314\n",
      "step:60, train_loss: 0.3147452771663666\n",
      "step:70, train_loss: 0.2739475131034851\n",
      "step:80, train_loss: 0.2522972285747528\n",
      "step:90, train_loss: 0.23953257799148558\n",
      "step:100, train_loss: 0.22505950331687927\n",
      "step:110, train_loss: 0.19935805201530457\n",
      "step:120, train_loss: 0.17690134048461914\n",
      "PHASE: val\n",
      "step: 0, val_loss: 0.21154260635375977, val dice_score: 0.7884573936462402\n",
      "step: 1, val_loss: 0.2014142870903015, val dice_score: 0.7985857129096985\n",
      "step: 2, val_loss: 0.21596616506576538, val dice_score: 0.7840338349342346\n",
      "step: 3, val_loss: 0.1701037883758545, val dice_score: 0.8298962116241455\n",
      "step: 4, val_loss: 0.19283920526504517, val dice_score: 0.8071607947349548\n",
      "step: 5, val_loss: 0.20474237203598022, val dice_score: 0.7952576279640198\n",
      "step: 6, val_loss: 0.18002265691757202, val dice_score: 0.819977343082428\n",
      "step: 7, val_loss: 0.19996803998947144, val dice_score: 0.8000319600105286\n",
      "step: 8, val_loss: 0.21326923370361328, val dice_score: 0.7867307662963867\n",
      "step: 9, val_loss: 0.2073938250541687, val dice_score: 0.7926061749458313\n",
      "step: 10, val_loss: 0.1865115761756897, val dice_score: 0.8134884238243103\n",
      "step: 11, val_loss: 0.18213492631912231, val dice_score: 0.8178650736808777\n",
      "step: 12, val_loss: 0.21764463186264038, val dice_score: 0.7823553681373596\n",
      "step: 13, val_loss: 0.20443427562713623, val dice_score: 0.7955657243728638\n",
      "step: 14, val_loss: 0.19998472929000854, val dice_score: 0.8000152707099915\n",
      "step: 15, val_loss: 0.20049399137496948, val dice_score: 0.7995060086250305\n",
      "step: 16, val_loss: 0.22727727890014648, val dice_score: 0.7727227210998535\n",
      "step: 17, val_loss: 0.2103680968284607, val dice_score: 0.7896319031715393\n",
      "step: 18, val_loss: 0.20348095893859863, val dice_score: 0.7965190410614014\n",
      "step: 19, val_loss: 0.19387710094451904, val dice_score: 0.806122899055481\n",
      "step: 20, val_loss: 0.16713255643844604, val dice_score: 0.832867443561554\n",
      "mean val_loss: 0.1995524905976795\n",
      "validation set dice_score: 0.8004474639892578\n",
      "best dice_score on val set: 0.8004474639892578\n",
      "Epoch 1/99\n",
      "----------\n",
      "PHASE: train\n",
      "step:10, train_loss: 0.16833032369613649\n",
      "step:20, train_loss: 0.15195000171661377\n",
      "step:30, train_loss: 0.12384951114654541\n",
      "step:40, train_loss: 0.13358601927757263\n",
      "step:50, train_loss: 0.1031434714794159\n",
      "step:60, train_loss: 0.10132330656051636\n",
      "step:70, train_loss: 0.09373703598976135\n",
      "step:80, train_loss: 0.09245725274085999\n",
      "step:90, train_loss: 0.09860299825668335\n",
      "step:100, train_loss: 0.09406576156616211\n",
      "step:110, train_loss: 0.09430428147315979\n",
      "step:120, train_loss: 0.07851828336715698\n",
      "PHASE: val\n",
      "step: 0, val_loss: 0.08621340990066528, val dice_score: 0.9137865900993347\n",
      "step: 1, val_loss: 0.08285564184188843, val dice_score: 0.9171443581581116\n",
      "step: 2, val_loss: 0.06958919763565063, val dice_score: 0.9304108023643494\n",
      "step: 3, val_loss: 0.08422964811325073, val dice_score: 0.9157703518867493\n",
      "step: 4, val_loss: 0.07417893409729004, val dice_score: 0.92582106590271\n",
      "step: 5, val_loss: 0.08761429786682129, val dice_score: 0.9123857021331787\n",
      "step: 6, val_loss: 0.08576905727386475, val dice_score: 0.9142309427261353\n",
      "step: 7, val_loss: 0.06780099868774414, val dice_score: 0.9321990013122559\n",
      "step: 8, val_loss: 0.09729468822479248, val dice_score: 0.9027053117752075\n",
      "step: 9, val_loss: 0.0642891526222229, val dice_score: 0.9357108473777771\n",
      "step: 10, val_loss: 0.08107483386993408, val dice_score: 0.9189251661300659\n",
      "step: 11, val_loss: 0.06977254152297974, val dice_score: 0.9302274584770203\n",
      "step: 12, val_loss: 0.07142388820648193, val dice_score: 0.9285761117935181\n",
      "step: 13, val_loss: 0.07488811016082764, val dice_score: 0.9251118898391724\n",
      "step: 14, val_loss: 0.0814620852470398, val dice_score: 0.9185379147529602\n",
      "step: 15, val_loss: 0.08435004949569702, val dice_score: 0.915649950504303\n",
      "step: 16, val_loss: 0.07991564273834229, val dice_score: 0.9200843572616577\n",
      "step: 17, val_loss: 0.08254736661911011, val dice_score: 0.9174526333808899\n",
      "step: 18, val_loss: 0.06467586755752563, val dice_score: 0.9353241324424744\n",
      "step: 19, val_loss: 0.09478622674942017, val dice_score: 0.9052137732505798\n",
      "step: 20, val_loss: 0.061057984828948975, val dice_score: 0.938942015171051\n",
      "mean val_loss: 0.07837093444097609\n",
      "validation set dice_score: 0.9216290712356567\n",
      "best dice_score on val set: 0.9216290712356567\n",
      "Epoch 2/99\n",
      "----------\n",
      "PHASE: train\n",
      "step:10, train_loss: 0.07245343327522277\n",
      "step:20, train_loss: 0.07744590044021607\n",
      "step:30, train_loss: 0.07607694268226624\n",
      "step:40, train_loss: 0.07493998408317566\n",
      "step:50, train_loss: 0.06768662333488465\n",
      "step:60, train_loss: 0.05518206357955933\n",
      "step:70, train_loss: 0.0680304229259491\n",
      "step:80, train_loss: 0.05676097273826599\n",
      "step:90, train_loss: 0.05780926942825317\n",
      "step:100, train_loss: 0.05970854163169861\n",
      "step:110, train_loss: 0.05210400819778442\n",
      "step:120, train_loss: 0.0532417893409729\n",
      "PHASE: val\n",
      "step: 0, val_loss: 0.04322361946105957, val dice_score: 0.9567763805389404\n",
      "step: 1, val_loss: 0.05930948257446289, val dice_score: 0.9406905174255371\n",
      "step: 2, val_loss: 0.04682636260986328, val dice_score: 0.9531736373901367\n",
      "step: 3, val_loss: 0.04954332113265991, val dice_score: 0.9504566788673401\n",
      "step: 4, val_loss: 0.05895638465881348, val dice_score: 0.9410436153411865\n",
      "step: 5, val_loss: 0.05180549621582031, val dice_score: 0.9481945037841797\n",
      "step: 6, val_loss: 0.06696361303329468, val dice_score: 0.9330363869667053\n",
      "step: 7, val_loss: 0.05262303352355957, val dice_score: 0.9473769664764404\n",
      "step: 8, val_loss: 0.047734975814819336, val dice_score: 0.9522650241851807\n",
      "step: 9, val_loss: 0.0368158221244812, val dice_score: 0.9631841778755188\n",
      "step: 10, val_loss: 0.04080665111541748, val dice_score: 0.9591933488845825\n",
      "step: 11, val_loss: 0.05369234085083008, val dice_score: 0.9463076591491699\n",
      "step: 12, val_loss: 0.036361873149871826, val dice_score: 0.9636381268501282\n",
      "step: 13, val_loss: 0.06870043277740479, val dice_score: 0.9312995672225952\n",
      "step: 14, val_loss: 0.03847503662109375, val dice_score: 0.9615249633789062\n",
      "step: 15, val_loss: 0.046439528465270996, val dice_score: 0.953560471534729\n",
      "step: 16, val_loss: 0.06242626905441284, val dice_score: 0.9375737309455872\n",
      "step: 17, val_loss: 0.03976947069168091, val dice_score: 0.9602305293083191\n",
      "step: 18, val_loss: 0.04985225200653076, val dice_score: 0.9501477479934692\n",
      "step: 19, val_loss: 0.06533980369567871, val dice_score: 0.9346601963043213\n",
      "step: 20, val_loss: 0.057072222232818604, val dice_score: 0.9429277777671814\n",
      "mean val_loss: 0.05108276151475452\n",
      "validation set dice_score: 0.9489172101020813\n",
      "best dice_score on val set: 0.9489172101020813\n",
      "Epoch 3/99\n",
      "----------\n",
      "PHASE: train\n",
      "step:10, train_loss: 0.05539454817771912\n",
      "step:20, train_loss: 0.0496860146522522\n",
      "step:30, train_loss: 0.05131239295005798\n",
      "step:40, train_loss: 0.0485971987247467\n",
      "step:50, train_loss: 0.04920728206634521\n",
      "step:60, train_loss: 0.051636630296707155\n",
      "step:70, train_loss: 0.05424486994743347\n",
      "step:80, train_loss: 0.05742881894111633\n",
      "step:90, train_loss: 0.052366513013839724\n",
      "step:100, train_loss: 0.04770553112030029\n",
      "step:110, train_loss: 0.050475478172302246\n",
      "step:120, train_loss: 0.047194600105285645\n",
      "PHASE: val\n",
      "step: 0, val_loss: 0.049946129322052, val dice_score: 0.950053870677948\n",
      "step: 1, val_loss: 0.06957530975341797, val dice_score: 0.930424690246582\n",
      "step: 2, val_loss: 0.034284770488739014, val dice_score: 0.965715229511261\n",
      "step: 3, val_loss: 0.04395955801010132, val dice_score: 0.9560404419898987\n",
      "step: 4, val_loss: 0.040170907974243164, val dice_score: 0.9598290920257568\n",
      "step: 5, val_loss: 0.035423099994659424, val dice_score: 0.9645769000053406\n",
      "step: 6, val_loss: 0.057587265968322754, val dice_score: 0.9424127340316772\n",
      "step: 7, val_loss: 0.041660308837890625, val dice_score: 0.9583396911621094\n",
      "step: 8, val_loss: 0.04893213510513306, val dice_score: 0.9510678648948669\n",
      "step: 9, val_loss: 0.03355848789215088, val dice_score: 0.9664415121078491\n",
      "step: 10, val_loss: 0.029384613037109375, val dice_score: 0.9706153869628906\n",
      "step: 11, val_loss: 0.036870718002319336, val dice_score: 0.9631292819976807\n",
      "step: 12, val_loss: 0.04854297637939453, val dice_score: 0.9514570236206055\n",
      "step: 13, val_loss: 0.03707921504974365, val dice_score: 0.9629207849502563\n",
      "step: 14, val_loss: 0.031571269035339355, val dice_score: 0.9684287309646606\n",
      "step: 15, val_loss: 0.039116084575653076, val dice_score: 0.9608839154243469\n",
      "step: 16, val_loss: 0.06160968542098999, val dice_score: 0.93839031457901\n",
      "step: 17, val_loss: 0.033325374126434326, val dice_score: 0.9666746258735657\n",
      "step: 18, val_loss: 0.05791592597961426, val dice_score: 0.9420840740203857\n",
      "step: 19, val_loss: 0.04061233997344971, val dice_score: 0.9593876600265503\n",
      "step: 20, val_loss: 0.034406423568725586, val dice_score: 0.9655935764312744\n",
      "mean val_loss: 0.04312059992835635\n",
      "validation set dice_score: 0.9568793177604675\n",
      "best dice_score on val set: 0.9568793177604675\n",
      "Epoch 4/99\n",
      "----------\n",
      "PHASE: train\n",
      "step:10, train_loss: 0.05158928632736206\n",
      "step:20, train_loss: 0.0543821930885315\n",
      "step:30, train_loss: 0.06428361535072327\n",
      "step:40, train_loss: 0.05089378356933594\n",
      "step:50, train_loss: 0.06480972170829773\n",
      "step:60, train_loss: 0.05436137318611145\n",
      "step:70, train_loss: 0.04723997116088867\n",
      "step:80, train_loss: 0.04862887859344482\n",
      "step:90, train_loss: 0.04533119201660156\n",
      "step:100, train_loss: 0.05893408060073853\n",
      "step:110, train_loss: 0.06020979285240173\n",
      "step:120, train_loss: 0.051364737749099734\n",
      "PHASE: val\n",
      "step: 0, val_loss: 0.05152624845504761, val dice_score: 0.9484737515449524\n",
      "step: 1, val_loss: 0.049282193183898926, val dice_score: 0.9507178068161011\n",
      "step: 2, val_loss: 0.035250842571258545, val dice_score: 0.9647491574287415\n",
      "step: 3, val_loss: 0.039950788021087646, val dice_score: 0.9600492119789124\n",
      "step: 4, val_loss: 0.04097241163253784, val dice_score: 0.9590275883674622\n",
      "step: 5, val_loss: 0.04746907949447632, val dice_score: 0.9525309205055237\n",
      "step: 6, val_loss: 0.04416239261627197, val dice_score: 0.955837607383728\n",
      "step: 7, val_loss: 0.0436016321182251, val dice_score: 0.9563983678817749\n",
      "step: 8, val_loss: 0.05918985605239868, val dice_score: 0.9408101439476013\n",
      "step: 9, val_loss: 0.06738513708114624, val dice_score: 0.9326148629188538\n",
      "step: 10, val_loss: 0.04579281806945801, val dice_score: 0.954207181930542\n",
      "step: 11, val_loss: 0.05676686763763428, val dice_score: 0.9432331323623657\n",
      "step: 12, val_loss: 0.04828989505767822, val dice_score: 0.9517101049423218\n",
      "step: 13, val_loss: 0.036472320556640625, val dice_score: 0.9635276794433594\n",
      "step: 14, val_loss: 0.03740650415420532, val dice_score: 0.9625934958457947\n",
      "step: 15, val_loss: 0.04286026954650879, val dice_score: 0.9571397304534912\n",
      "step: 16, val_loss: 0.056765973567962646, val dice_score: 0.9432340264320374\n",
      "step: 17, val_loss: 0.044363975524902344, val dice_score: 0.9556360244750977\n",
      "step: 18, val_loss: 0.062168896198272705, val dice_score: 0.9378311038017273\n",
      "step: 19, val_loss: 0.029848337173461914, val dice_score: 0.9701516628265381\n",
      "step: 20, val_loss: 0.050044476985931396, val dice_score: 0.9499555230140686\n",
      "mean val_loss: 0.047122424557095484\n",
      "validation set dice_score: 0.9528777003288269\n",
      "Epoch 5/99\n",
      "----------\n",
      "PHASE: train\n",
      "step:10, train_loss: 0.04247331619262695\n",
      "step:20, train_loss: 0.04439690113067627\n",
      "step:30, train_loss: 0.04165346622467041\n",
      "step:40, train_loss: 0.05294143557548523\n",
      "step:50, train_loss: 0.04296639561653137\n",
      "step:60, train_loss: 0.04870340824127197\n",
      "step:70, train_loss: 0.04252101182937622\n",
      "step:80, train_loss: 0.035324198007583615\n",
      "step:90, train_loss: 0.04068338871002197\n",
      "step:100, train_loss: 0.0427584171295166\n",
      "step:110, train_loss: 0.054261142015457155\n",
      "step:120, train_loss: 0.04466991424560547\n",
      "PHASE: val\n",
      "step: 0, val_loss: 0.030378878116607666, val dice_score: 0.9696211218833923\n",
      "step: 1, val_loss: 0.03703826665878296, val dice_score: 0.962961733341217\n",
      "step: 2, val_loss: 0.04490470886230469, val dice_score: 0.9550952911376953\n",
      "step: 3, val_loss: 0.037397682666778564, val dice_score: 0.9626023173332214\n",
      "step: 4, val_loss: 0.03824484348297119, val dice_score: 0.9617551565170288\n",
      "step: 5, val_loss: 0.03629577159881592, val dice_score: 0.9637042284011841\n",
      "step: 6, val_loss: 0.03846961259841919, val dice_score: 0.9615303874015808\n",
      "step: 7, val_loss: 0.037322819232940674, val dice_score: 0.9626771807670593\n",
      "step: 8, val_loss: 0.036901891231536865, val dice_score: 0.9630981087684631\n",
      "step: 9, val_loss: 0.039977848529815674, val dice_score: 0.9600221514701843\n",
      "step: 10, val_loss: 0.04751741886138916, val dice_score: 0.9524825811386108\n",
      "step: 11, val_loss: 0.0354350209236145, val dice_score: 0.9645649790763855\n",
      "step: 12, val_loss: 0.04276561737060547, val dice_score: 0.9572343826293945\n",
      "step: 13, val_loss: 0.03247708082199097, val dice_score: 0.967522919178009\n",
      "step: 14, val_loss: 0.054286301136016846, val dice_score: 0.9457136988639832\n",
      "step: 15, val_loss: 0.028108179569244385, val dice_score: 0.9718918204307556\n",
      "step: 16, val_loss: 0.04386425018310547, val dice_score: 0.9561357498168945\n",
      "step: 17, val_loss: 0.027258574962615967, val dice_score: 0.972741425037384\n",
      "step: 18, val_loss: 0.040087103843688965, val dice_score: 0.959912896156311\n",
      "step: 19, val_loss: 0.03996467590332031, val dice_score: 0.9600353240966797\n",
      "step: 20, val_loss: 0.0311773419380188, val dice_score: 0.9688226580619812\n",
      "mean val_loss: 0.03808923278536115\n",
      "validation set dice_score: 0.9619109034538269\n",
      "best dice_score on val set: 0.9619109034538269\n",
      "Epoch 6/99\n",
      "----------\n",
      "PHASE: train\n",
      "step:10, train_loss: 0.03626703023910523\n",
      "step:20, train_loss: 0.042536860704421996\n",
      "step:30, train_loss: 0.047873389720916745\n",
      "step:40, train_loss: 0.04272655844688415\n",
      "step:50, train_loss: 0.03950697183609009\n",
      "step:60, train_loss: 0.04087694883346558\n",
      "step:70, train_loss: 0.044665515422821045\n",
      "step:80, train_loss: 0.03820277452468872\n",
      "step:90, train_loss: 0.04232848286628723\n",
      "step:100, train_loss: 0.04266243577003479\n",
      "step:110, train_loss: 0.04427875876426697\n"
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean([np.array(10, dtype = np.float32), np.array(20, dtype = np.float32), np.array(30, dtype = np.float32)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_dir = \"data/Lung_Segmentation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCUCXR_0001_0.png\n",
    "# CHNCXR_0001_0.png --- CHNCXR_0001_0_mask.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list = os.listdir(os.path.join(root_dir, \"images\"))\n",
    "masks_list = os.listdir(os.path.join(root_dir, \"masks\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"dataset.csv\", \"w\")\n",
    "count = 0\n",
    "for img in images_list:\n",
    "    img_name = img.split(\".png\")[0]\n",
    "    if img.startswith(\"CHNCXR\"):\n",
    "        mask_name = \"{}_mask.png\".format(img_name)\n",
    "    elif img.startswith(\"MCUCXR\"):\n",
    "        mask_name = img\n",
    "    if os.path.exists(os.path.join(root_dir, \"masks\", mask_name)):\n",
    "        f.write(\"{}, {}\\n\".format(img, mask_name))\n",
    "        count +=1\n",
    "    \n",
    "f.close()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = open(\"dataset.csv\", \"r\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
